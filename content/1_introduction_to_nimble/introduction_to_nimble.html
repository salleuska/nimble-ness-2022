<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to NIMBLE</title>
    <meta charset="utf-8" />
    <meta name="author" content="NIMBLE Development Team" />
    <script src="libs/header-attrs-2.14/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Introduction to NIMBLE
]
.subtitle[
## NIMBLE NESS 2022 short course
]
.author[
### NIMBLE Development Team
]
.date[
### May 2022
]

---




# What Is NIMBLE?

**N**umerical **I**nference for statistical **M**odels using **B**ayesian and **L**ikelihood **E**stimation.
--
.pull-left[
![](nimble-icon.png)
]

.pull-right[
![](nimble-jackalope.png)
]

---
# What Is NIMBLE?

**N**umerical **I**nference for statistical **M**odels using **B**ayesian and **L**ikelihood **E**stimation.


- A framework for hierarchical statistical models and methods.

- A nearly drop-in alternative to WinBUGS, OpenBUGS and JAGS.

- An extension of the BUGS language for writing new functions and distributions.

- A configurable system for MCMC.

- A library of other methods.
    - Sequential Monte Carlo (particle filtering) (via the `nimbleSMC` package)
    - Monte Carlo Expectation Maximization (maximum likelihood)

- A model-generic programming system to write new analysis methods.

---

### NIMBLE components

* Model language: A new, extended dialect of BUGS/JAGS for specifying models

* A package of algorithms (MCMC, SMC, MCEM)

* Algorithm language: nimbleFunctions, embedded within R for writing algorithms

* Compiler: Generates and compiles C++ from models and algorithms
---
# Why NIMBLE?

Here are some of the features you can do in NIMBLE that we are most excited about and that distinguish NIMBLE from other software:

- customize your MCMCs, including choosing what parameters to block

- define your own distributions and functions for use in BUGS code

- use a variety of algorithms on your model, including MCMC, sequential Monte Carlo (particle filtering), and MCEM

- write an algorithm in our system for easy dissemination to others, including your own MCMC samplers

- call out to arbitrary external (C++, R, etc.) code within a model or algorithm

- compile mathematical operations in R without needing to know or write C or C++
---
# Why not NIMBLE?

- For MCMCs that rely heavily on Gibbs sampling, JAGS may be a bit faster because of more efficient internal implementation of the calculations.

- For certain model structures, Hamiltonian Monte Carlo, such as implemented in Stan or PyMC3, may work better than the default MCMC samplers in NIMBLE.
   1. That said, in a number of examples we've tried we've been able to achieve comparable or better performance either out-of-the-box or with some relatively simple modifications to the model or the MCMC samplers.
   2. And yet, sometimes customization is time-consuming and requires specialized knowledge.
  
- NIMBLE can take a long time to build algorithms for models that have tens of thousands or more nodes (though once built, the algorithm run times can be quite good). We anticipate big improvements in future versions of NIMBLE.

---
# Getting help with NIMBLE

* User manual ([html](https://r-nimble.org/html_manual/cha-welcome-nimble.html) or [pdf](https://r-nimble.org/manuals/NimbleUserManual.pdf))

* Post to the [NIMBLE user group](https://groups.google.com/forum/#!forum/nimble-users)

* If necessary, email [nimble.stats@gmail.com](the NIMBLE development team)

* Follow announcements via the [NIMBLE announcements list](https://groups.google.com/forum/#!forum/nimble-announce)

---

## A basic example

Here we'll give a simple example of building a model and running a default MCMC. Other modules will show how one can fit the model and give more detail on various features of NIMBLE.

We'll use the *litters* model example from BUGS. The data set describes survival of rat pups in a simple experiment.

  - There are `G=2` groups of rat litters, with `N=16` litters (i.e., mothers) in each group, and a variable number of pups in each litter.

  - Survival of the pups in a litter is governed by a survival probability for each litter, `p[i,j]`.
  
  - The probabilities for the litters within a group are considered to come from a common distribution, thereby borrowing strength across the litters in a group.
  
  - The common distributions are `\(p_{1,j} \sim \mbox{Beta}(a_1, b_1)\)` for group 1 and `\(p_{2,j} \sim \mbox{Beta}(a_2, b_2)\)` for group 2.


---

## Specifying the code for a model

Here we specify the litters code directly in R. We can walk through some of details via the comments in the BUGS code. The model is a binomial GLMM with `\(G=2\)` groups of rat litters, and exchangeable litter-specific survival probabilities for the litters in each group. 


```r
library(nimble)
```

```
## nimble version 0.12.2 is loaded.
## For more information on NIMBLE and a User Manual,
## please visit https://R-nimble.org.
```

```
## 
## Attaching package: 'nimble'
```

```
## The following object is masked from 'package:stats':
## 
##     simulate
```

```r
littersCode &lt;- nimbleCode({
    for (i in 1:G) {
        for (j in 1:N) {
            # Likelihood (data model)
            r[i, j] ~ dbin(p[i, j], n[i, j])
            # Latent process (random effects)
            p[i, j] ~ dbeta(a[i], b[i])
        }
        # Priors for hyperparameters (this parameterization
        # not recommended)
        a[i] ~ dgamma(1, 0.001)
        b[i] ~ dgamma(1, 0.001)
    }
})
```

You can also load it directly from the standard BUGS example file formats (see `help(readBUGSmodel)`).

---
# Build the model


```r
## data and constants as R objects
G &lt;- 2
N &lt;- 16
n &lt;- matrix(c(13, 12, 12, 11, 9, 10, 9, 9, 8, 11, 8, 10, 13,
    10, 12, 9, 10, 9, 10, 5, 9, 9, 13, 7, 5, 10, 7, 6, 10, 10,
    10, 7), nrow = 2)
r &lt;- matrix(c(13, 12, 12, 11, 9, 10, 9, 9, 8, 10, 8, 9, 12, 9,
    11, 8, 9, 8, 9, 4, 8, 7, 11, 4, 4, 5, 5, 3, 7, 3, 7, 0),
    nrow = 2)

littersConsts &lt;- list(G = G, N = N, n = n)
littersData &lt;- list(r = r)
littersInits &lt;- list(a = c(2, 2), b = c(2, 2))
```

---



```r
## create the NIMBLE model object
littersModel &lt;- nimbleModel(littersCode, data = littersData,
    constants = littersConsts, inits = littersInits)
```

```
## Defining model
```

```
## Building model
```

```
## Setting data and initial values
```

```
## Running calculate on model
##   [Note] Any error reports that follow may simply reflect missing values in model variables.
```

```
## Checking model sizes and dimensions
```

```
##   [Note] This model is not fully initialized. This is not an error.
##          To see which variables are not initialized, use model$initializeInfo().
##          For more information on model initialization, see help(modelInitialization).
```

If all you want to do is run an MCMC, NIMBLE's fine-grained control might not be so interesting to you, in which case you can just use `nimbleMCMC()` without using `nimbleModel()` to create the model. But by providing an explicit model object, we allow you to operate the model and program with it.

---
# Compiling a model

In general, you'll want a version of the model that allows for fast computation (this can then be used by any algorithms you use on the model).

To create a fast compiled version of the model, you simply do this.


```r
cLittersModel &lt;- compileNimble(littersModel)
```

```
## Compiling
##   [Note] This may take a minute.
##   [Note] Use 'showCompilerOutput = TRUE' to see C++ compilation details.
```
---
# Operating a model

You can view and manipulate the values of variables in the model, and calculate (prior or likelihood) densities and simulate from the prior or likelihood in a model.

(Note that the initial NA values for *p* explain the earlier message about the model not being fully initialized.)


```r
cLittersModel$p
cLittersModel$calculate("a")  # log-prior density
cLittersModel$getLogProb("a")

cLittersModel$a &lt;- c(3, 3)
cLittersModel$calculate("a")  # updated log-prior density

set.seed(1)  # so the calculations are reproducible
littersModel$simulate("p")  # simulate from prior
littersModel$p
littersModel$getLogProb("p")  # log prob not yet updated!
littersModel$calculate("p")  # update it
littersModel$getLogProb("p")  # now we're good
```

---
# Setting up an MCMC such that it could be customized

Much of the power of NIMBLE comes from the ability to **customize algorithms**, including how MCMC sampling works.

In order to talk about MCMC customization later today, we first need to see the 'manual' steps of running an MCMC in NIMBLE (as a contrast to the one-click MCMC mentioned in a previous slide).

The steps of running an MCMC are as follows:

 1. configure the MCMC (via `configureMCMC()`)
 2. build the MCMC (via `buildMCMC()`)
 3. create a compiled version of the MCMC (via `compileNimble()`)
 4. run the MCMC (via `runMCMC()`)
 5. assess and use the MCMC samples (e.g., using CODA tools)

Note that `nimbleMCMC()` combines steps 1-4 (and in fact does not even require you to create the model). See the last slide.

---
# Configuring a basic MCMC

At a high level, NIMBLE (like BUGS and JAGS) uses a "Gibbs" style MCMC that loops over parameters.

  - Individual samplers (e.g., conjugate, Metropolis, slice, etc.) are assigned to individual parameters or blocks of parameters.

  - In contrast, Stan and PyMC3 assign a Hamiltonian Monte Carlo sampler to the entire vector of parameters. 

  - Setting up and running an MCMC in NIMBLE in this way takes a few more steps than in BUGS or JAGS, but with the benefit of giving the user much more control of how the MCMC operates.
---

First we *configure* the MCMC, which means setting up the samplers to be used for each node or group of nodes. NIMBLE provides a default configuration, but we'll see shortly how you can modify that. 


```r
littersConf &lt;- configureMCMC(littersModel, print = TRUE)
```

```
## ===== Monitors =====
## thin = 1: a, b
## ===== Samplers =====
## RW sampler (4)
##   - a[]  (2 elements)
##   - b[]  (2 elements)
## conjugate sampler (32)
##   - p[]  (32 elements)
```
You also specify the nodes for which you'd like to get the MCMC samples as output. (NIMBLE defaults to only monitoring the "top-level" nodes, i.e., hyperparameters with no stochastic parents.)


```r
littersConf$addMonitors(c("a", "b", "p"))
```

```
## thin = 1: a, b, p
```

---

# Building the MCMC algorithm for the model 

Next we'll build the MCMC algorithm for the model under the default configuration. And we'll create a compiled (i.e., C++) version of the MCMC that is equivalent in functionality but will run much faster.


```r
littersMCMC &lt;- buildMCMC(littersConf)
cLittersMCMC &lt;- compileNimble(littersMCMC, project = littersModel)
```

```
## Compiling
##   [Note] This may take a minute.
##   [Note] Use 'showCompilerOutput = TRUE' to see C++ compilation details.
```

(The *project* argument helps us manage all the C++ that is generated for a given analysis. In general the project can be referenced using the name of the original (uncompiled) model.)

---

# Running the MCMC

Now let's run the MCMC.


```r
niter &lt;- 5000
nburn &lt;- 1000
set.seed(1)
inits &lt;- function() {
    a &lt;- runif(G, 1, 20)
    b &lt;- runif(G, 1, 20)
    p &lt;- rbind(rbeta(N, a[1], b[1]), rbeta(N, a[2], b[2]))
    return(list(a = a, b = b, p = p))
}
samples &lt;- runMCMC(cLittersMCMC, niter = niter, nburnin = nburn,
    inits = inits, nchains = 3, samplesAsCodaMCMC = TRUE)
```

```
## Running chain 1 ...
```

```
## |-------------|-------------|-------------|-------------|
## |-------------------------------------------------------|
```

```
## Running chain 2 ...
```

```
## |-------------|-------------|-------------|-------------|
## |-------------------------------------------------------|
```

```
## Running chain 3 ...
```

```
## |-------------|-------------|-------------|-------------|
## |-------------------------------------------------------|
```

Sidenote: We don't recommend running the R version of the MCMC for very many iterations - it's really slow - in part because iterating in R is slow and in part because iterating with a model in NIMBLE requires even more overhead. The R and C MCMC samples are the same, so you can use the R MCMC for debugging. It's possible to step through the code line by line using R's debugging capabilities (not shown).

---

# Working with MCMC output

Now let's look at the MCMC performance from one of the chains.


```r
samples1 &lt;- samples[[1]]

par(mfrow = c(2, 2), mai = c(0.6, 0.5, 0.4, 0.1), mgp = c(1.8,
    0.7, 0))
ts.plot(samples1[, "a[1]"], xlab = "iteration", ylab = expression(a[1]),
    main = expression(a[1]))
ts.plot(samples1[, "b[1]"], xlab = "iteration", ylab = expression(b[1]),
    main = expression(b[1]))
ts.plot(samples1[, "a[2]"], xlab = "iteration", ylab = expression(a[2]),
    main = expression(a[2]))
ts.plot(samples1[, "b[2]"], xlab = "iteration", ylab = expression(b[2]),
    main = expression(b[2]))
```

---

![](introduction_to_nimble_files/figure-html/output-mcmc-1.png)

Not good. We'll explore different sampling strategies that fix the problems in later modules.

---
# Using CODA

NIMBLE does not provide any MCMC diagnostics. (At least not yet; there's no reason one couldn't write code for various diagnostics using the NIMBLE system.)  But one can easily use CODA or other R packages with the MCMC output from a NIMBLE MCMC.


```r
library(coda, warn.conflicts = FALSE)
crosscorr(samples1[, c("a[1]", "b[1]", "a[2]", "b[2]")])
```

```
##           a[1]      b[1]      a[2]      b[2]
## a[1] 1.0000000 0.8343044 0.2624355 0.2602005
## b[1] 0.8343044 1.0000000 0.2088233 0.1629184
## a[2] 0.2624355 0.2088233 1.0000000 0.8303567
## b[2] 0.2602005 0.1629184 0.8303567 1.0000000
```

```r
head(effectiveSize(samples1))  ## ESS
```

```
##       a[1]       a[2]       b[1]       b[2]    p[1, 1]    p[2, 1] 
##   7.310760  86.232010   8.946092  60.987165  96.220013 616.282469
```

---
# Assessing MCMC performance from multiple chains

To apply the commonly used Gelman-Rubin potential scale reduction factor diagnostic, we'll need the multiple chains.


```r
head(gelman.diag(samples))
```

```
## $psrf
##          Point est. Upper C.I.
## a[1]      2.2162849  4.2886833
## a[2]      1.0065774  1.0241670
## b[1]      2.3811165  7.6199187
## b[2]      1.0207793  1.0474280
## p[1, 1]   1.2348221  1.6466767
## p[2, 1]   1.0017367  1.0057803
## p[1, 2]   1.2342585  1.6452188
## p[2, 2]   1.0005385  1.0018228
## p[1, 3]   1.2188054  1.6080112
## p[2, 3]   1.0033499  1.0103608
## p[1, 4]   1.2115466  1.5904925
## p[2, 4]   1.0001902  1.0012278
## p[1, 5]   1.2194506  1.6100929
## p[2, 5]   0.9999531  1.0004980
## p[1, 6]   1.2202988  1.6118662
## p[2, 6]   1.0000543  1.0007217
## p[1, 7]   1.2161367  1.6013571
## p[2, 7]   1.0011609  1.0045178
## p[1, 8]   1.1804320  1.5138645
## p[2, 8]   1.0003467  1.0010550
## p[1, 9]   1.1884292  1.5332161
## p[2, 9]   1.0007071  1.0026822
## p[1, 10]  1.1985794  1.5588287
## p[2, 10]  1.0010180  1.0032841
## p[1, 11]  1.1884981  1.5334401
## p[2, 11]  1.0001338  1.0004044
## p[1, 12]  1.1733039  1.4960784
## p[2, 12]  1.0006119  1.0017001
## p[1, 13]  1.1776475  1.5079383
## p[2, 13]  0.9998300  0.9998316
## p[1, 14]  1.1631354  1.4706534
## p[2, 14]  1.0014119  1.0040368
## p[1, 15]  1.1362107  1.4021162
## p[2, 15]  1.0028499  1.0085630
## p[1, 16]  1.1321746  1.3936554
## p[2, 16]  1.0035323  1.0129760
## 
## $mpsrf
## [1] 1.93866
```

---


```r
par(mfrow = c(1, 1))
## and here's a graphical representation of the information
par(mfrow = c(1, 2))
ts.plot(samples[[1]][, "a[1]"], xlab = "iteration", ylab = expression(a[1]),
    main = expression(a[1]))
sq &lt;- seq_along(samples[[1]][, "a[1]"])
for (i in 2:3) lines(sq, samples[[i]][, "a[1]"], col = i)
ts.plot(samples[[1]][, "b[1]"], xlab = "iteration", ylab = expression(b[1]),
    main = expression(b[1]))
sq &lt;- seq_along(samples[[1]][, "b[1]"])
for (i in 2:3) lines(sq, samples[[i]][, "b[1]"], col = i)
```
---

![](introduction_to_nimble_files/figure-html/gelman-rubin-1.png)

---

# Other MCMC tools in NIMBLE

  - WAIC for model comparison

  - variable selection via reversible jump MCMC

  - cross-validation 

  - (coming soon) calibrated posterior predictive p-values

---

# One-click MCMC operation: `nimbleMCMC`


```r
samples &lt;- nimbleMCMC(code = littersCode, data = littersData,
    inits = littersInits, constants = littersConsts, monitors = c("a",
        "b", "p"), thin = 1, niter = 1100, nburnin = 100, nchains = 1,
    setSeed = TRUE)
```

```
## Defining model
```

```
## Building model
```

```
## Setting data and initial values
```

```
## Running calculate on model
##   [Note] Any error reports that follow may simply reflect missing values in model variables.
```

```
## Checking model sizes and dimensions
```

```
##   [Note] This model is not fully initialized. This is not an error.
##          To see which variables are not initialized, use model$initializeInfo().
##          For more information on model initialization, see help(modelInitialization).
```

```
## Checking model calculations
```

```
## [Note] NAs were detected in model variables: p, logProb_p, logProb_r.
```

```
## Compiling
##   [Note] This may take a minute.
##   [Note] Use 'showCompilerOutput = TRUE' to see C++ compilation details.
```

```
## Running chain 1 ...
```

```
## |-------------|-------------|-------------|-------------|
## |-------------------------------------------------------|
```

--- 


```r
par(mfrow = c(2, 2), cex = 1.2, mgp = c(1.8, 0.7, 0), mai = c(0.75,
    0.75, 0.1, 0.1))
ts.plot(samples[, "a[1]"], xlab = "iteration", ylab = expression(a[1]))
ts.plot(samples[, "a[2]"], xlab = "iteration", ylab = expression(a[2]))
ts.plot(samples[, "b[1]"], xlab = "iteration", ylab = expression(b[1]))
ts.plot(samples[, "b[2]"], xlab = "iteration", ylab = expression(b[2]))
```

---

![](introduction_to_nimble_files/figure-html/litters-nimbleMCMC-1.png)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
